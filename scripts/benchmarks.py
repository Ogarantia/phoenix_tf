"""
#### Analysis Functions
# low level bench by operation or integrated in a very small NN
collect_res_by_op/nn:
      collect data in a log file from all python script finishing by "_bench.py" (resp. "_bench_nn.op")
      these tests files should only contain one operation
      to test in the same way small NN, a second function is called to run all python script finishing by "_bench_nn.py"
generate_graph_by_op/nn:
      Use results in log files generated by "collect_res_by_op" to generate graphs that are saved in a res folder.
      Under the hood, it calls all scripts finishing by "bench_visu.py", which should correspond to one "<op>_bench.py".
      All bench_visu.py should be implement using the same pattern and generate files in the same folder etc.
# High level bench
generate_tensorboard_train_nn:
      Run all train scripts in tests/python_high_level_tests/; the name must start by "train_"
      All results are sent to {context["resdir"]}/log_<file_name>
generate_tensorboard_infer_nn:
      Same as previously, but with inference tests; the name must start by "inf_"
      All results are sent to {context["resdir"]}/log_<file_name>
# High high level tests using specific architectures
generate_classification_api_infer_results:
      Clone classification-api repository and run inference_benchmark.py,
      in order to get results in {context["resdir"]}
# To run all the functions above
generate_results:
      Run all above functions

#### Misc Functions
get_system_info:
  Return a list of information about the system (Architecture and OS); more will be added in the future
get_available_gpus:
  Return the list of available gpus, empty list if no gpu were found.
get_project_path:
  Get path to current project. By default look for the name "phoenix_tf"
get_lib_path:
  Get the path to _upstride.so
pretty_print:
  Protect your eyes from bleeding reading ugly messages
fill_context:
  Fill all fields of the context map
execute_command:
  Executes a command at the root of the project and returns its stdout
add_readme_info:
  Add a message in context["resdir"]/README.txt
pack_results:
  Compress results as a tar file and move it to context["resdir"]
create_config_file_template:
  Generates a configuration template file

#### GIT functions / engine functions
get_git_revisions_hash:
  Get the full hash
get_git_branch_name:
  Specify a branch name
compile_engine:
  Compile an engine from scratch
update_engine:
  Pull from a specific commit

#### OS functions
 modify_python_path:
    Change the python path to set the one for the engine you would like to bench
 set_gpu_use:
    Set a specific env var to tell on which GPU(s) you would like to run
 get_compilation_flags:
    Get compilation flags used to compile libupstride.so
 setup_env:
    Pip install few modules that can missing to run benchs/tests
 print_generic_info:
    Print information about the system and the OS
 write_generic_info:
    Write generic information in a context["resdir"]/INFO.txt file
 print_error:
    Print error message using red color
 print_warning:
    Print warning message using yellow color
 print_info:
    Print information message using grey background
 print_dbg:
    Print debug message only when debug mode is enabled

### Run example
# Run interactive mode that gonna ask to you to fill all information about what you want to run
python3 benchmarks.py -i
# Run benchmarks on the latest commit of the master branch, distclean and compile, then run all bench using the _upstride.so of the project
python3 benchamrks.py --branch=master --update=True --gen_all_res --lib_path=/path/to/_upstride.so
# Generate all results possible using default information we have
python3 benchamrks.py -gar
"""
import functools    # static function
import nvgpu        # to get gpu info
import subprocess   # to run cmd, get printed log and check if process went fine or not
import platform     # to extract systel information
import os           # to run os.path.join, or os.system
import sys          # to manage PYTHONPATH
import argparse     # to parse input args
import configparser # to parse config files
import datetime     # datetime.datetime.now()
import platform     # platform and CPU info

# or any {'0', '1', '2'} # disable Tensorflow warning and message
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

context = {
  "project_name": "phoenix_tf", # project's name; /!\ Beware, here it represents the name of the root folder of the project.
                                # If you put phoenix_tf in /opt/src in your docker, so the project_name should be "src"
  "device": "GPU",    # On which device you would like to compile/execture the engine
  "commit": "master", # Branch, tag or commit's hash
  "resdir": ".",      # Set path where you would like to push your results.
  "lib_path": [],     # path to the _upstride.so
  "engines": [],      # engines to compare
  "tensorflow": "",   # Just for consistency
  "py-upstride": "",  # Path to the python engine (i.e. upstride_python)
  "px-upstride": "",  # Python Path to the phoenix engine (i.e. phoenix_tf/src/python)
  "list_op": [],      # list of operations can contains also #epochs and batch_size as follow list_op["file"]={"batch_size"=bs, "epochs"=nb_epochs}
  "config_file": "",  # Instead of writing arguments you can provide a configuration file where all fields are already filled
  "mem_use_limit": 20,# GPU memory limit percent from where you consider it as usable
  "classification_arch_infer": [], # List all architecture to test with classification-api for inference
  "classification_arch_train": [], # List all architecture to test with classification-api for training
  "orig_pythonpath": "",  # Save the PYTHONPATH env variable before we run this script
  "multi-gpu": False,
  ## ENV CONTEXT
  "DEBUG": True,      # Allow to print all debug messages
  "VERBOSE": 5,       # Determine the verbose level; 0 completely silent, 1 only error messages, 2 add warning messages, 3 add info messages, 4 add debug messages
  "batch_size_init":0 # If zero, the default initial batch size is kept. Otherwise, it is overwritten.
}

SUCCESS = 0
ERROR = 1
MEM_ERROR = 2

########################################
##         OS/GIT information         ##
########################################

@functools.lru_cache(maxsize=1)
def get_project_path():
  """Extract path to the <project name> root
  """
  path = os.path.abspath(os.getcwd())
  path = os.path.join(path.split(context["project_name"])[0], context["project_name"])
  return path


@functools.lru_cache(maxsize=1)
def get_lib_path():
  return context["lib_path"] if context["lib_path"] else os.path.join(get_project_path(), "build/libs")


@functools.lru_cache(maxsize=1)
def get_git_revisions_hash():
  """Return the current commit hash
  """
  return execute_command('git rev-parse HEAD')


@functools.lru_cache(maxsize=1)
def get_git_branch_name():
  """Return current branch name
  """
  branch_name = execute_command('git branch')
  return branch_name.split("* ", 1)[-1].split("\n", 1)[0]


@functools.lru_cache(maxsize=1)
def get_system_info():
  """Return following system information - current architecture and current operating system
  """
  return [platform.machine(), platform.platform()]


@functools.lru_cache(maxsize=1)
def get_available_gpus():
  """Return list of GPU indices that use less than mem_use_limit_persents% of its capacity or an empty list if no GPU is free
  """
  try:
    gpu_list_info = nvgpu.gpu_info()
    return [gpu["index"] for gpu in gpu_list_info if gpu["mem_used_percent"] < context["mem_use_limit"]]
  except:
    return []


def modify_python_path(engine="", path="", clean=False):
  """Append sys.path in order to choose the right engine.
  """
  if clean:
    os.environ['PYTHONPATH'] = ""

  # Set PYTHONPATH env variable
  myenv = os.environ.copy()
  if engine:
    for eng in context["engines"]:
      if eng["name"] == engine:
        myenv['PYTHONPATH'] = eng["pythonpath"]
  elif path:
    myenv['PYTHONPATH'] = path
  return myenv


def set_gpu_use(list_of_gpu_indices):
  """Export the list of GPU indices to use in the CUDA_VISIBLE_DEVICES env var
  """
  gpus = ",".join(list_of_gpu_indices)
  os.environ["CUDA_VISIBLE_DEVICES"] = gpus


# For example git@bitbucket.org:upstride/upstride_python.git
def clone_bitbucket_repos(repos_name):
  project_parent_path = os.path.join(get_project_path(), '../')
  repository_path = os.path.join(project_parent_path, repos_name)
  
  if not os.path.exists(repository_path):
    subprocess.check_output(['git',
                              'clone',
                            f'git@bitbucket.org:upstride/{repos_name}.git'],
                            cwd=project_parent_path)
    subprocess.check_output(['git',
                              'submodule',
                              'update',
                              '--init',
                              '--recursive'],
                            cwd=repository_path)


# for example git@github.com:UpStride/classification-api.git
def clone_git_repos(repos_name):
  project_parent_path = os.path.join(get_project_path(), '../')
  repository_path = os.path.join(project_parent_path, repos_name)
  
  if not os.path.exists(repository_path):
    subprocess.check_output(['git',
                              'clone',
                            f'git@github.com:UpStride/{repos_name}.git'],
                            cwd=project_parent_path)
    subprocess.check_output(['git',
                              'submodule',
                              'update',
                              '--init',
                              '--recursive'],
                            cwd=repository_path)

# def docker_run(): # TODO in a future version

# def docker_create(): # TODO in a future version

########################################
##         Results Generation         ##
########################################


def collect_res_by_op(clean_all=True, clean=[]):
  """List operation to bench, run them and generate a log file that will be used by generate_graph_by_op later.
     Append all operations managed into the context list_op.
  Argument
      clean_all: remove associated log file before running benchmarks
      clean: List of log files to clean; file name is expected be the one of the run, not the log name
  """
  script_path = os.path.join(get_project_path(), 'scripts')
  print_info(f"Running all scripts *_bench.py in {script_path}")
  # find all files named *_bench.py and run them
  files = [f for f in os.listdir(script_path) if os.path.isfile(os.path.join(script_path, f))]
  if not files:
    print_warning(f"Beware, no file ending by \"_bench.py\" found in {script_path}")
  for f in files:
    if f.endswith("_bench.py"):
      file_path = os.path.join(script_path, f)
      op_name = f.replace('_bench.py', '')
      fname = os.path.splitext(f)[0]
      print_info(f"Run {f}")
      
      if not os.path.exists(os.path.join(context["resdir"], op_name)):
        os.makedirs(os.path.join(context["resdir"], op_name))

      logfile_withpath = os.path.join(context["resdir"], op_name, f'log_{fname}.log')
      # remove _bench.py to get only the op name from the file name.
      if  os.path.exists(logfile_withpath) and (clean_all or f in clean):
        os.system(f'rm {logfile_withpath}')

      # Set env for the phoenix engine 
      myenv = modify_python_path(engine="px-upstride")

      with open(logfile_withpath, 'a') as logfile:
        logfile.write("Execution Output: \n")
        print_dbg(f'python3 {file_path} --logdir={context["resdir"]}')
        logtxt = subprocess.Popen(['python3',
                                    file_path,
                                    f'--logdir={context["resdir"]}'],
                                stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE,
                                env=myenv)
        for line in logtxt.stdout:
          logfile.write(line.decode('utf-8'))
        _, err = logtxt.communicate()
        if err: 
          print_error(f'During the collection of data of {op_name}. See {logfile_withpath} for more information.')
          logfile.write(err.decode('utf-8'))


      print_info(f"Add {op_name} to the list of operations.")
      context["list_op"].append(op_name)
      print_dbg(f'List of operations: {context["list_op"]}')


def generate_graph_by_op():
  """ Generate graph from results obtained previously from collect_res_by_op
  """
  script_path = os.path.join(get_project_path(), 'scripts')
  print_info(f"Generate results using the bench_visu.py scripts in {script_path}")
  # find all files names *_bench_op_visu.py and call them to generate associated graphs
  files = [f for f in os.listdir(script_path) if os.path.isfile(f'{script_path}/{f}')]
  if not files:
    print_warning(f"Beware, no file \"bench_visu.py\" found in {script_path}")
  for f in files:
    for op in context["list_op"]:
      if f.endswith(f'{op}_bench_visu.py'):
        print_info(f"Generate graph for {op} with  {script_path}/{f}")
        try:
          print_dbg(f'python3 {script_path}/{f} --logdir={context["resdir"]} --op={op}')
          subprocess.check_output(['python3',
                                  f'{script_path}/{f}',
                                  f'--logdir={context["resdir"]}',
                                  f'--op={op}'],
                              cwd=script_path)
        except:
          print_error(f'{op} failed. Please look previous message for more information.')


def generate_gpu_profile(script_path_with_name, where=get_project_path()):
  """ Generate gpu profiling using nsys or nvprof on an operation in paramter
  Command line example:
      $   nsys profile -o profetch.prof  --stats=true python3 tests/python_high_level_tests/train_simple_network_quaternions.py
      or
      $   nvprof -o profetch.prof python3 tests/python_high_level_tests/train_simple_network_quaternions.py  

  Not use yet be cause I'm not sure on what to run it, but will be very usefull soon.
  Should also work on CPU but we can find more appropriated tools (Intel VTune ?).
  """
  operation_name = script_path_with_name.split("\\", 1)[0]
  operation_path = script_path_with_name.split("\\", 1)[-1]
  if os.system('nsys') == 0:
    add_readme_info(f'Run nsys profile -o {os.path.join(context["resdir"], "prefetch.prof")} in {operation_path}')
    print_info(subprocess.check_output(['nsys',
                                        'profile',
                                        '-o',
                                        os.path.join(context["resdir"],"prefetch.prof"),
                                        'python3',
                                        operation_name],
                                    cwd=operation_path))
  elif os.system('nvprof'):
    add_readme_info(f'Run nvprof -o {os.path.join(context["resdir"], "prefetch.prof")} in {operation_path}')
    print_info(subprocess.check_output(['nvprof',
                                        '-o',
                                        os.path.join(context["resdir"],"prefetch.prof"),
                                        'python3',
                                        operation_name],
                                    cwd=operation_path))
  add_readme_info(f'To visualize results please open {context["resdir"]}/prefetch.prof with your NVIDIA Visual Profiler')


def create_engine_configs(context):
  """ Create a list of engines assosiated with their possible value for dtype
  """
  engine_configs = []
  for engines in context["engines"]:
    for dtype in engines["dtype"]:
      engine_configs.append({"name": engines["name"],
                              "dtype": dtype,
                              "pythonpath": engines["pythonpath"]})
  return engine_configs


def generate_tensorboard_train_nn(epochs=2, batch_size=1024, list_of_files=[]):
  """Run all train_*.py files in tests/python_high_level_tests/
     these files should be able to execute tensorboard and move files in "--logdir=context["resdir"]/log_{filename}"
  """
  batch_size = batch_size if context["batch_size_init"] == 0 else context["batch_size_init"]
  script_path = os.path.join(get_project_path(), 'tests', 'python_high_level_tests')
  print_info(f"[Small NN] Generating results using all training scripts in {script_path}")
  # Error key words that appear every time a error is raised with python
  # Far to be perfect but at least it's something ¯\_(ツ)_/¯
  errorKeywords = "Traceback (most recent call last)"
  # Decrease batch_size only when it crashed due to lack of memory
  errorMemoryLack = ["out of memory", "Cannot allocate output tensor", "CUDNN_STATUS_ALLOC_FAILED"]
  # find all files named train_*.py and fcall them to generate associated graphs
  # these files have been either requested in list_of_files or their name started with "train_"
  files = [f for f in os.listdir(script_path) if os.path.isfile(f'{script_path}/{f}')]
  if not files:
    print_warning(f"Beware, no file of type \"train_*.py\" found in {script_path}")

  engine_configs_initial = create_engine_configs(context)
  engine_configs = []
  for engine_config in engine_configs_initial: # Adding 'train' argument, which is specific to train_model.py
    for train in [1, 0.5, 0]:
      engine_configs.append(dict(engine_config))
      engine_configs[-1]["train"] = train

  for f in files:
    if list_of_files and f not in list_of_files:
        continue
    elif not f.startswith("train_"):
        continue

    # if the user define which file use to bench, we check if he also defined specific batch_size and number of epochs
    batch_size_r = list_of_files[f]["batch_size"] if f in list_of_files and list_of_files[f]["batch_size"] else batch_size
    epochs_r     = list_of_files[f]["epochs"]     if f in list_of_files and list_of_files[f]["epochs"]     else epochs

    print_info(f"Generation results from  {f}")
    fname = os.path.splitext(f)[0]

    # Looking for a batch_size that fit to the GPU.
    # By default it takes 1024 as maximum to test and divide by two each time it fails until it reaches a batch_size equals to 1.
    look_for_batchsize = True
    while look_for_batchsize:
      look_for_batchsize = True
      memory_error = False
      for engine in engine_configs:
        # Set names for logs
        logdir_name  = f'log_{engine["name"]}-{engine["dtype"]}_{fname}_{context["device"]}'
        logfile_name = f'log_{engine["name"]}-{engine["dtype"]}_{fname}_bs{batch_size_r}_{context["device"]}.log'
        logdir = os.path.join(context["resdir"], logdir_name)
            
        # Clean previous noisy results
        if os.path.exists(logdir):
            subprocess.check_output(['rm', '-rf', f'{context["resdir"]}/{logdir_name}'])
        os.makedirs(logdir)

        # Set PYTHONPATH env variable
        myenv = modify_python_path(path=engine["pythonpath"])
        # Run cmd with the selected engine
        upstride_bool = 1 if engine["name"] == "px-upstride" else 0
        python_command = f'PYTHONPATH={engine["pythonpath"]} python3 {script_path}/{f} --upstride={upstride_bool} --datatype={engine["dtype"]} --logdir={logdir} --epochs={epochs} --train={engine["train"]} --batch_size={batch_size_r}'
        print_dbg(f'{python_command} 2>&1 {logdir}/{logfile_name}')
        with open(os.path.join(logdir, logfile_name), 'a') as logfile:
          logfile.write(f'Run: {python_command} \n')
          logfile.write("Execution Output: \n")
          logtxt = subprocess.Popen(['python3', f'{script_path}/{f}',
                                    f'--upstride={upstride_bool}',
                                    f'--datatype={engine["dtype"]}',
                                    f'--logdir={logdir}',
                                    f'--epochs={epochs_r}',
                                    f'--train={engine["train"]}',
                                    f'--batch_size={batch_size_r}'],
                                    cwd=script_path,
                                    stdout=subprocess.PIPE,
                                    stderr=subprocess.PIPE,
                                    env=myenv)
          while True:
            line = logtxt.stdout.readline().decode('utf-8')
            if not line: break
            sys.stdout.write(line)  # print in standard output
            logfile.write(line)
          # Catch if an error was raised
          _, err = logtxt.communicate()
          if errorKeywords in err.decode('utf-8'):
            print(err.decode('utf-8'))
            logfile.write(err.decode('utf-8'))
            print_warning(f"[Small NN] Batch_size of {batch_size_r} is not working for {f}.")
            # If the error is "out of memory" let's try with a smaller batch_size
            if batch_size_r > 1:
              for key in errorMemoryLack:
                if key in err.decode('utf-8'):
                  print_warning("It seems related to a lack of memory. We will try with a batch_size twice smaller.")
                  batch_size_r = int(batch_size_r/2)
                  memory_error = True
              if memory_error:
                break
            else:
              print_error("No \"batch_size\" works, so either your test is too greedy either the problem came from something else. Please check errors messages above.")
              look_for_batchsize = False
          else:
            add_readme_info(f'[Small NN] Sucess on {f} with {engine["name"]}. \nTo visualize results please run: \ntensorboard --logdir {logdir}/{logdir_name}')
      look_for_batchsize = True if memory_error else False


def generate_classification_api_infer_results():
  """Download classification-api from bitbucket if it doesn't already exist in scripts/
     Then, if there is a config.yml file, use it to provide parameters. Otherwise, run fixed parameters
     This part of the script will be improved in the future: we will take more information in the context to provide here
  """
  if context["device"] == "CPU":
    print_error(f'Error: Sorry, all classification-api runs cannot be executed on {context["device"]}.')
    return

  project_parent_path = os.path.join(get_project_path(), '../')
  repository_path = os.path.join(project_parent_path, 'classification-api')

  # Clone imagnet-baseline
  clone_git_repos(repos_name='classification-api')

  # TODO: Test with config file
  # The config file is currently searched here: ../classification-api/config.yml
  if os.path.exists(os.path.join(repository_path, 'config.yml')):
    print("Using config.yml")
    print(subprocess.check_output(['python3',
                                    f'{repository_path}/inference_benchmark.py',
                                    f'--yaml_config={repository_path}/config.yml']))
  else:
    batch_size = 128
    docker_img = 'local'

    engine_configs = create_engine_configs(context)

    # For all models defined by the user, run with all good parameters. 
    # If a memory error is catched, then restart for all engines with a smaller batch_size
    # If the error came from something else we continue to the next engine/model
    # If success add all information for the user into the readme file at the root of resdir
    for model in context["classification_arch_infer"]:
      batch_size_r = batch_size if context["batch_size_init"] == 0 else context["batch_size_init"]

      # create path for results
      results_dir = os.path.join(context["resdir"], 'classification-infer', model)
      if not os.path.exists(results_dir):
          os.makedirs(results_dir)

      look_for_batchsize = True
      while look_for_batchsize:
        for engine in engine_configs:
          factor = 4 if engine["dtype"] == 2 else 1
          engine_name = engine["name"]
          engine_name_orig = engine["name"]
          dtype = engine["dtype"]
          if "-upstride" in engine_name:
            engine_name = engine_name + f'_{dtype}-f{factor}'

          # Clean PYTHONPATH and add path to the px-upstride
          myenv = modify_python_path(path=engine["pythonpath"], clean=True)

          # Create the list of args to pass
          args_list = ['python3',
                      f'{repository_path}/inference_benchmark.py',
                      '--batch_size', batch_size_r,
                      '--cpu', 'True' if context["device"] == "CPU" else 'False',
                      '--docker_images', docker_img,
                      '--models', model,
                      '--engines', engine_name,
                      '--output', os.path.join(results_dir, f'{engine_name_orig}_res.txt')
                      ]

          # Run the Phoenix engine
          print_dbg(f"python3 {repository_path}/inference_benchmark.py " 
                    f"--batch_size {batch_size_r} "
                      "--cpu 'False' "
                    f"--docker_images {docker_img} "
                    f"--models {model} "
                    f"--engines {engine_name} "
                    f"--output {os.path.join(results_dir, f'{engine_name_orig}_res.txt')} "
                    f"2&>1 {os.path.join(results_dir, f'log_inf_benchmark_{engine_name_orig}_{dtype}_bs{batch_size_r}.log')}")
            # Run CMD
          status = execute_popen_in_log(logfile_w_path=os.path.join(results_dir, f'log_inf_benchmark_{engine_name_orig}_{dtype}_bs{batch_size_r}.log'), 
                                        cmd=args_list, cwd=repository_path, env=myenv)
          
          # Check status to know what to do next
          if status == SUCCESS:
            add_readme_info(f'[classification-api] Sucess on {model} with {engine_name}.'
                            f'Results are in {os.path.join(results_dir, f"log_inf_benchmark_{engine_name_orig}_{dtype}_bs{batch_size_r}.log")} ')
            look_for_batchsize = False
          elif status == ERROR: # 
            print_error(f'Error when running {engine["name"]} with {dtype}')
            print_warning(f'Batch_size of {batch_size_r} is not working for {model}.')
            look_for_batchsize = False
          elif status == MEM_ERROR:
            print_error(f'Error when running {engine["name"]} with {dtype}')
            print_warning(f'Batch_size of {batch_size_r} is not working for {model}.')
            print_warning('It seems related to a lack of memory. We will try with a batch_size twice smaller.')
            batch_size_r = int(batch_size_r/2)
            look_for_batchsize = True
            break
          else:
            print_error(f'Error when running {engine["name"]} with {dtype}')
            print_error(f'Return status not known.')


def generate_classification_api_train_results():
  """Download classification-api from bitbucket if it doesn't already exist in project_path()/../
     Then, if there is a config.yml file, use it to provide parameters. Otherwise, run fixed parameters
     This part of the script will be improved in the future: we will take more information in the context to provide here
  """
  if context["device"] == "CPU":
    print_error(f'Error: Sorry, Classification-api is not made to be executed on {context["device"]}. \nStop training.')
    return

  project_parent_path = os.path.join(get_project_path(), '../')
  repository_path = os.path.join(project_parent_path, 'classification-api')

  # Clone classification-api
  clone_git_repos(repos_name='classification-api')

  # TODO: Test with config file
  # The config file is currently searched here: ../classification-api/config.yml
  if os.path.exists(os.path.join(repository_path, 'config.yml')):
    print("Using config.yml")
    print(subprocess.check_output(['python3',
                                    f'{repository_path}/train.py',
                                    f'--yaml_config={repository_path}/config.yml']))
  else:
    train_configurations = []
    if "MobileNetV2Cifar10NCHW" in context["classification_arch_train"]:
      train_configurations.append ( # MobileNetV2Cifar10NCHW - cifar10
      {
        "model_name": "MobileNetV2Cifar10NCHW",
        "data_name": "cifar10",
        "num_class": 10,
        "input_size_H": 32, "input_size_W": 32, "input_size_C": 3,
        "data_train_list": ['RandomHorizontalFlip','Translate','Cutout','Normalize'],
        "data_val_list": ['Normalize'],
        "data_val_split_id": "test",
        "data_trans_width_shift_range": 0.25,
        "data_trans_height_shift_range": 0.25,
        "data_cutout_length": 4,
        "early_stopping": 40,
        "optimizer_lr": 0.1,
        "optimizer_lr_decay_strat_patience": 20,
        "optimizer_lr_decay_strat_strategy": "lr_reduce_on_plateau",
        "optimizer_lr_decay_strat_decay_rate": 0.3
      })
    if "MobileNetV2NCHW" in context["classification_arch_train"]:
      # It does not make much sense to use Mobilenet with cifar100. Commenting for the moment
      # TODO: Decide its destiny
      # train_configurations.append ( # MobileNetV2NCHW - cifar100
      # {
      #     "model_name": "MobileNetV2NCHW",
      #     "data_name": "cifar100",
      #     "num_class": 100,
      #     "input_size_H": 32, "input_size_W": 32, "input_size_C": 3,
      #     "data_train_list": ['RandomHorizontalFlip','Translate','Cutout','Normalize'],
      #     "data_val_list": ['Normalize'],
      #     "data_val_split_id": "test",
      #     "data_trans_width_shift_range": 0.25,
      #     "data_trans_height_shift_range": 0.25,
      #     "data_cutout_length": 4,
      #     "early_stopping": 40,
      #     "optimizer_lr": 0.1,
      #     "optimizer_lr_decay_strat_patience": 20,
      #     "optimizer_lr_decay_strat_strategy": "lr_reduce_on_plateau",
      #     "optimizer_lr_decay_strat_decay_rate": 0.3
      # })
      train_configurations.append ({ # MobileNetV2NCHW - imagenette/full-size-v2
        "model_name": "MobileNetV2NCHW",
        "data_name": "imagenette/full-size-v2",
        "num_class": 10,
        "batch_size": 4,
        "early_stopping": 40
      })
      # Prepare stuff for imagenet but not tested and validated yet
      # train_configurations.append (
      # {
      #     "model_name": "MobileNetV2NCHW",
      #     "data_name": "imagenet",
      #     "num_class": 1000,
      #     "input_size_H": 224, "input_size_W": 224, "input_size_C": 3,
      #     "data_train_list": ['ResizeThenRandomCrop','RandomHorizontalFlip','Translate','Cutout','Normalize'],
      #     "data_val_list": ['ResizeThenRandomCrop','Normalize'],
      #     "data_val_split_id": "validation",
      #     "data_trans_width_shift_range": 0.25,
      #     "data_trans_height_shift_range": 0.25,
      #     "data_cutout_length": 4,
      #     "early_stopping": 40,
      #     "optimizer_lr": 0.1,
      #     "optimizer_lr_decay_strat_patience": 20,
      #     "optimizer_lr_decay_strat_strategy": "lr_reduce_on_plateau",
      #     "optimizer_lr_decay_strat_decay_rate": 0.3
      # })
    
    # Create a list of engines assosiated with their possible value for dtype
    engine_configs = create_engine_configs(context)
    batch_size = 128
    nb_epochs=1000

    for train_config in train_configurations:
      batch_size_r = batch_size if context["batch_size_init"] == 0 else context["batch_size_init"]
      # create path for results
      results_dir = os.path.join(context["resdir"], 'classification-train', train_config["model_name"])
      if not os.path.exists(results_dir):
          os.makedirs(results_dir)
      # Call the train.py script
      # Parameters that can either be defined in a config file or by ourselves
      # The config file is currently searched here: scripts/classification-api/config.yml
      look_for_batchsize = True
      while look_for_batchsize:
        for engine in engine_configs:
          factor = 4 if engine["dtype"] == 2 else 1
          dtype = engine["dtype"]
          if "-upstride" in engine["name"]:
            type_name = "type" + str(dtype)
            engine_name = "upstride_" + type_name
          else:
            engine_name = engine["name"]

          # Clean PYTHONPATH and add path to the px-upstride
          myenv = modify_python_path(path=engine["pythonpath"], clean=True)

          # Create the list of args to pass
          args_list = ['python3', 
                      f'{repository_path}/train.py',
                        '--model_name', train_config["model_name"],
                        '--framework', engine_name,
                        '--factor', factor,
                        '--num_epochs', nb_epochs,
                        '--checkpoint_dir', os.path.join(results_dir,"checkpoint/"),
                        '--log_dir', results_dir,
                        '--dataloader.batch_size', batch_size_r,
                        '--dataloader.name', train_config["data_name"],
                        '--early_stopping', train_config["early_stopping"]
                      ]
          # All of these parameters don't obviously appear when calling classification-api/train.py
          # So we have to check for each parameter
          if train_config["data_name"] != "imagenette/full-size-v2":
            if train_config["input_size_H"]:
              args_list.extend(['--input_size', train_config["input_size_H"], train_config["input_size_W"], train_config["input_size_C"]])
            if train_config["data_train_list"]:
              args_list.extend(['--dataloader.train_list', *train_config["data_train_list"]])
            if train_config["data_val_list"]:
              args_list.extend(['--dataloader.val_list', *train_config["data_val_list"]])
            if train_config["data_val_split_id"]:
              args_list.extend(['--dataloader.val_split_id', train_config["data_val_split_id"]])
            if train_config["data_trans_width_shift_range"]:
              args_list.extend(['--dataloader.Translate.width_shift_range', train_config["data_trans_width_shift_range"]])
            if train_config["data_trans_height_shift_range"]:
              args_list.extend(['--dataloader.Translate.height_shift_range', train_config["data_trans_height_shift_range"]])
            if train_config["data_cutout_length"]:
              args_list.extend(['--dataloader.Cutout.length', train_config["data_cutout_length"]])
            if train_config["optimizer_lr"]:
              args_list.extend(['--optimizer.lr', train_config["optimizer_lr"]])
            if train_config["optimizer_lr_decay_strat_patience"]:
              args_list.extend(['--optimizer.lr_decay_strategy.lr_params.patience', train_config["optimizer_lr_decay_strat_patience"]])
            if train_config["optimizer_lr_decay_strat_strategy"]:
              args_list.extend(['--optimizer.lr_decay_strategy.lr_params.strategy', train_config["optimizer_lr_decay_strat_strategy"]])
            if train_config["optimizer_lr_decay_strat_decay_rate"]:
              args_list.extend(['--optimizer.lr_decay_strategy.lr_params.decay_rate', train_config["optimizer_lr_decay_strat_decay_rate"]])
          if train_config["num_class"]:
            args_list.extend(['--num_classes', train_config["num_class"]])

          # Both cannot co-exist
          if context["multi-gpu"]:
            args_list.append('--configuration.mirrored')
          else:
            args_list.extend(['--configuration.profiler', 'True'])
          
          # Print cmd line used
          print_dbg(f"PYTHONPATH={myenv['PYTHONPATH']} {' '.join(list(map(str,args_list)))}")
          # Run CMD
          status = execute_popen_in_log(logfile_w_path=os.path.join(results_dir, f'log_train_benchmark_{engine["name"]}_{dtype}_bs{batch_size_r}.log'), cmd=args_list, cwd=repository_path, env=myenv)
          
          # Check status to know what to do next
          if status == SUCCESS:
            add_readme_info(f'[classification-api] Sucess on {train_config["model_name"]} with {engine["name"]}({type_name}). Results are in {results_dir}/log_train_benchmark_{engine["name"]}_{dtype}_bs{batch_size_r}.log')
            look_for_batchsize = False
          elif status == ERROR: # 
            print_error(f'Error when running {engine["name"]} with {type_name}')
            print_warning(f'Batch_size of {batch_size_r} is not working for {train_config["model_name"]}.')
            look_for_batchsize = False

          elif status == MEM_ERROR:
            print_error(f'Error when running {engine["name"]} with {type_name}')
            print_warning(f'Batch_size of {batch_size_r} is not working for {train_config["model_name"]}.')
            print_warning('It seems related to a lack of memory. We will try with a batch_size twice smaller.')
            batch_size_r = batch_size_r // 2
            look_for_batchsize = True if batch_size_r > 1 else False
            if look_for_batchsize:
              break
          else:
            print_error(f'Error when running {engine["name"]} with {type_name}')
            print_error(f'Return status not known.')


def generate_all_results(collect_op=True, generate_op=True, generate_nn=True, classification_infer=True, classification_train=True):
  print_info("****")
  print_info("Start generating results...")
  if collect_op:
    print_info("**")
    print_info("Collection data by operation...")
    collect_res_by_op()
  if generate_op:
    print_info("**")
    print_info("Generating graph by operation...")
    generate_graph_by_op()
  if generate_nn:
    print_info("**")
    print_info("Generating graph by training script...")
    generate_tensorboard_train_nn()
  if classification_infer:
    print_info("**")
    print_info("Generating results from classification-api (inference)...")
    generate_classification_api_infer_results()
  if classification_train:
    print_info("**")
    print_info("Generating results from classification-api (training)...")
    generate_classification_api_train_results()
  print_info("... End generating results")
  print_info("****")


########################################
##               Engine               ##
########################################

def compile_engine(full_clean=True, use_gpu=True):
  """Compile engine from sources
  """
  print_info(f'Compile the engine from {context["commit"]}')
  if full_clean:
    print(execute_command('make distclean'))
  else:
    print(execute_command('make clean'))
  if use_gpu:
    assert context["Device"].find("GPU") != -1, "No GPU is available and 'use_gpu' is set to True."
  enable_gpus = 'ON' if use_gpu else 'OFF'
  print(execute_command(f'make GPU={enable_gpus}'))
  print(execute_command('make install'))


def update_engine():
  """ Pull engine source from specific commit
  """
  print_info(f'Update the engine from {context["commit"]}')
  print(execute_command('git checkout ' + context["commit"]))
  print(execute_command('git pull --recurse-submodules'))


@functools.lru_cache(maxsize=1)
def get_compilation_flags():
  """ Extract compilation flags from the elf.
      It exist several way to do it.
      Not optimal and force us to compile with gcc :/
      String is not well cut yet, it just to have the string; maybe one day we should improve this function
      TODO find a better way to extract this operation, try with readelf for example as follow (this line is not working perfectly)
  # logtxt = subprocess.Popen(['readelf','-wi', get_lib_path(), '| grep DW_AT_producer'], 
  #                             cwd=os.path.join(get_project_path(),'scripts'), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
  """
  logtxt = subprocess.Popen(['strings', '-a', os.path.join(get_lib_path(), "_upstride.so")],
                            cwd=os.path.join(get_project_path(), 'scripts'), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
  return [line.decode('utf-8') for line in logtxt.stdout if line.decode('utf-8').find("GNU GIMPLE") != -1]


########################################
##                Misc                ##
########################################

def execute_command(cmd):
  """ Executes a command at the root of the project and returns its stdout.
  Raises CalledProcessError exception if its return code is not zero.
  """
  return subprocess.check_output(cmd.split(' '), cwd=get_project_path()).strip().decode('ascii')


def execute_popen_in_log(logfile_w_path, cmd, cwd, env=""):
  """ Executes a command at the root of the project and returns its stdout.
  Raises CalledProcessError exception if its return code is not zero.
  """
  # Error key words that appear every time a error is raised with python
  # Far to be perfect but at least it's something ¯\_(ツ)_/¯
  errorKeywords = "Traceback (most recent call last)"
  # List of possible errors related to a lack of memory
  errorMemoryLack = ["out of memory", "Cannot allocate output tensor", "CUDNN_STATUS_ALLOC_FAILED"]

  with open(logfile_w_path, 'a') as logfile:
    logfile.write("Execution Output: \n")
    logtxt = subprocess.Popen(map(str,cmd),
                            cwd=cwd,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                            env=env)
    while True:
      line = logtxt.stdout.readline().decode('utf-8')
      if not line: break
      if line:
        if line[-1] != '\r':
          # Throws away all the lines ending by '\r', namely the lines
          # displaying the evolution of a given epoch 
          logfile.write(line.split('\r')[-1]) # print in log file
        sys.stdout.write(line)  # print in standard output

    # Catch if an error was raised
    _, err = logtxt.communicate()
    if errorKeywords in err.decode('utf-8'):
      print(err.decode('utf-8'))
      logfile.write(err.decode('utf-8'))
      for key in errorMemoryLack:
        if key in err.decode('utf-8'):
          return MEM_ERROR
      else:
        print_error("Error: No batch_size works, so either your model"
                    " is too greedy either the problem came from something else.")
        add_readme_info("If all run, runs out of memory, try to add the following lines in you code:\n"
                        "gpus = tf.config.experimental.list_physical_devices('GPU')\n"
                        "for gpu in gpus:\n\ttf.config.experimental.set_memory_growth(gpu, True)\n")
        return ERROR
                  
  return SUCCESS


def print_error(str):
  if context["VERBOSE"] >= 0:
    print("\033[0;31m [Error]", str, "\033[1;37;39m")  # print in red


def print_warning(str):
  if context["VERBOSE"] >= 1:
    print("\033[0;33m [Warning]", str, "\033[1;37;39m")  # print in yellow


def print_info(str):
  if context["VERBOSE"] >= 2:
    print("\033[0;37;40m [INFO]", str, "\033[0;37;39m")  # print in cyan


def print_dbg(str):
  if context["DEBUG"] or context["VERBOSE"] >= 3:
    print("\033[0;36m [DBG]", str, "\033[0;37;39m")  # print in grey


def fill_context(config_file="", args=None,
               project_name="phoenix_tf", commit="master", 
               resdir="", 
               pxpath="", pypath="", 
               lib_path="",
               multigpu=False, 
               verbose=4):
  """Fill context in order to have all information needed to run all other functions

  Args:
      config_file (str, optional): configuration file with all information of the context. Defaults to "".
      args ([type], optional): Not used yet, but planed to be used to get all args from main and manage them here. Defaults to None.
      project_name (str, optional): The root folder name of the project. Defaults to "phoenix_tf".
      commit (str, optional): hash/branch name of the engine. Defaults to "master".
      resdir (str, optional): results directory where all results are put. Defaults to "".
      pxpath (str, optional): PYTHONPATH to the px-engine. Defaults to "".
      pypath (str, optional): PYTHONPATH to the py-engine. Defaults to "".
      lib_path (str, optional): Where to find .so. Defaults to "".
      multigpu (bool, optional): Enable multi-gpus, only available for training. Defaults to False.
      verbose (int, optional): Verbose level of this script, from 0 to 4. Defaults to 4.
  """
  # Save original PYTHONPATH env variable
  if 'PYTHONPATH' in os.environ:
    context["orig_pythonpath"] = os.environ['PYTHONPATH']
  if config_file == "":
    # Basic information
    context["project_name"] = project_name
    context["device"] = 'GPU' if get_available_gpus() else 'CPU'
    context["commit"] = commit
    # Fill engines en their path
    # Phoenix engine can managed scalar and type 2
    if pxpath and os.path.exists(pxpath):
      context["px-upstride"] = pxpath
      context["engines"].append({"name": "px-upstride",
                                  "dtype":[2,0],
                                  "pythonpath":pxpath})
    # Python-upstride only manage type 2 
    if pypath and os.path.exists(pypath):
      context["py-upstride"] = pypath
      context["engines"].append({"name": "py-upstride",
                                  "dtype":[2],
                                  "pythonpath":pypath})
    # Tensorflow scalar
    context["engines"].append({"name": "tensorflow",
                                "dtype":[0],
                                "pythonpath":""})
    context["lib_path"] = ""
    context["multi-gpu"] = multigpu
    # Where to put results
    context["resdir"] = "/tmp/res-phoenix-" + get_git_revisions_hash()[:6] if resdir == "" else resdir
    # Should we clear all previous results by default ?
    if os.path.exists(context["resdir"]):
      os.system(f'rm -rf {context["resdir"]}')
    os.makedirs(context["resdir"])
    context["VERBOSE"] = verbose
    if not context["classification_arch_infer"]:
      context["classification_arch_infer"] = ['AlexNetNCHW','MobileNetV2NCHW','MobileNetV2Cifar10NCHW']
  else:
    # TODO THIS PART HAS NOT BEEN TESTED, SO VERIFY IT WORKS AND THAT WE HAVE ALL INFORMATION NEEDED
    # User assume that all fileds are correct
    if not os.path.exists(config_file):
      print("Error: ", config_file, " doesn't exist.")
      exit(0)
    # Start to fill the context from config file
    context["config_file"] = config_file
    add_readme_info(f'[Init] fill information from {config_file}')
    
    config = configparser.ConfigParser()
    config.read(config_file)
    ### Project name
    context["project_name"] = config['project_name'] if 'project_name' in config else project_name
    ### GPU/CPU
    context["device"] = config['device'] if 'device' in config else 'GPU' if get_available_gpus() else 'CPU'
    if context["device"] == "GPU" and 'mem_use_limit' in config: context["mem_use_limit"] = config['mem_use_limit']
    ### Git 
    if 'commit'      in config: context["commit"] = config['commit']
    ## Engines
    if 'px-upstride' in config: context["engines"].append({"name": "px-upstride", "dtype":[2,0], "pythonpath":config['px-upstride']})
    if 'py-upstride' in config: context["engines"].append({"name": "py-upstride", "dtype":[2],   "pythonpath":config['py-upstride']})
    context["engines"].append({"name": "tensorflow", "dtype":[0], "pythonpath":""})
    # Results folder
    context["resdir"] = config['resdir'] if 'resdir' in config else "/tmp/res-phoenix-" + get_git_revisions_hash()[:6]
    if os.path.exists(context["resdir"]): os.system(f'rm -rf {context["resdir"]}')
    os.makedirs(context["resdir"])
    # SO files
    context["lib_path"] = config['lib_path'] if 'lib_path' in config else ''
    # Operations
    context["list_op"] = config['list_op'] if 'list_op'  in config else []
    context["classification_arch_infer"] = config["classification_arch_infer"] if "classification_arch_infer" in config else ['AlexNetNCHW','MobileNetV2NCHW','MobileNetV2Cifar10NCHW']
    context["classification_arch_train"] = config["classification_arch_train"] if "classification_arch_train" in config else ['MobileNetV2NCHW','MobileNetV2Cifar10NCHW']
    # System
    if 'multigpu'    in config: context["multi-gpu"] = config['multigpu']
    # CONTEXT
    if 'VERBOSE'     in config: context["VERBOSE"] = config['VERBOSE']
    if 'DEBUG'       in config: context["DEBUG"] = config['DEBUG']
  context["batch_size_init"] = args.batch_size_init


def setup_env():
  """ Setup your pip environment to be able to run bench (it's mainly to avoid to crash because it only missing these install)
  """
  subprocess.check_output(['python3', '-m', 'pip', '--disable-pip-version-check', 'install', 'seaborn']) # required by collect_res_by_op and generate_graph_by_op
  subprocess.check_output(['python3', '-m', 'pip', '--disable-pip-version-check', 'install', 'keras-tuner']) # required by generate_tensorboard_train_nn
  subprocess.check_output(['python3', '-m', 'pip', '--disable-pip-version-check', 'install', 'upstride_argparse']) # required by generate_classification_api_train_results
  subprocess.check_output(['python3', '-m', 'pip', '--disable-pip-version-check', 'install', 'opencv-python']) # required by generate_classification_api_train_results
  subprocess.check_output(['python3', '-m', 'pip', '--disable-pip-version-check', 'install', 'tensorflow-datasets']) # required by generate_classification_api_train_results
  subprocess.check_output(['python3', '-m', 'pip', '--disable-pip-version-check', 'install', 'tensorflow-addons']) # required by generate_classification_api_train_results


def print_generic_info():
  """ To protect your eyes from all ugly message and other prints
  """
  print("=======================")
  print("= GENERIC INFORMATION =")
  print("=======================")
  print("Project name: ", {context["project_name"]})
  print("From ", get_project_path())
  print("Result directory: ", context["resdir"])
  print("Engines path: ")
  print("Phoenix: ",context["px-upstride"])
  print("Python : ",context["py-upstride"])
  print("-----------------------")
  print("Phoenix lib information: ")
  print("Branch: ", get_git_branch_name())
  print("Git current hash: ", get_git_revisions_hash())
  print("Libraries location: ", context["lib_path"])
  print("Compilation flags: ", get_compilation_flags())
  print("-----------------------")
  print("Sys info: \n", get_system_info())
  found_gpu = context["device"].find("GPU") != -1
  if found_gpu:
    print("Device: [GPUs] - ", get_available_gpus())
    if context["multi-gpu"]:
      print("Multi-GPU: ON")
    else:
      print("Multi-GPU: OFF")
  else:
    print("Device: CPU")
  print("Proc: ", platform.processor())
  print("=======================")


def write_generic_info():
  """Write context anf system information in a specific file in the results dire. Such as, we can find how and where the run has been executed
  """
  if not os.path.exists(context["resdir"]):
    os.makedirs(context["resdir"])

  with open(os.path.join(context["resdir"], 'INFO.txt'), 'w') as info:
    info.writelines('===============================\n')
    info.writelines('==           CONTEXT         ==\n')
    info.writelines('===============================\n')
    info.writelines(f'Project name: {context["project_name"]}\n')
    info.writelines(f'Branch: {get_git_branch_name()}\n')
    info.writelines(f'Commit hash: {get_git_revisions_hash()}\n')
    info.writelines("System info: \n")
    info.writelines(f'Platform: {platform.system()}')
    info.write('\nMore info: ')
    info.writelines(["%s " % item for item in get_system_info()])
    info.write('\n')
    info.write("Device -")
    if context["device"] == "GPU":
      info.write(" GPUs:")
      info.writelines(f'[{",".join(get_available_gpus())}]')
    else:
      info.writelines(" CPU: ")
      info.writelines(platform.processor())
    info.write('\n')
    info.writelines(f'Compilation flags: {get_compilation_flags()}\n')
    info.writelines(f'Libs: {context["lib_path"]}')
    info.write('\n')
    info.writelines("Engines path: \n")
    info.writelines(f'  px-upstride path: {context["px-upstride"]}\n')
    info.writelines(f'  py-upstride path: {context["py-upstride"]}\n')
    info.writelines('===============================\n')
    info.write('\n')


def add_readme_info(message):
  """Add a message into resdir/README.txt

  Args:
      message (str): Message to write into the README
  """
  with open(os.path.join(context["resdir"], 'README.txt'), 'w') as info:
    info.write(message)


def pack_results():
  """Compress results directory in order to get/send/copy/read it later
  """
  print("pack results in ", context["resdir"])
  if not os.path.exists(context['resdir']):
    print_error("No results to pack.")
  else:
    try:
      date = str(datetime.datetime.now())[:10]
      execute_command(f'tar -zcvf benchmarks_phoenix_{get_git_revisions_hash()[:6]}_{date}.tar.gz {context["resdir"]}')
      execute_command(f'chmod 644 benchmarks_phoenix_{get_git_revisions_hash()[:6]}_{date}.tar.gz')
      execute_command(f'mv benchmarks_phoenix_{get_git_revisions_hash()[:6]}_{date}.tar.gz {context["resdir"]}')
      print_info(f'An archive with all results is available here: \n{context["resdir"]}/benchmarks_phoenix_{get_git_revisions_hash()[:6]}_{date}.tar.gz')
    except:
      print_error("Results haven't been packed. Please check error message above for more information.")


def create_config_file_template():
  """Create a configuration file template
  """
  config = configparser.ConfigParser()
  config["project_name"] = "phoenix_tf"
  config["device"] = "GPU"
  config["commit"] = "master"
  config["resdir"] = "/tmp/res"
  config["lib_path"] = ""
  config["px-upstride"] = ""
  config["py-upstride"] = ""
  config["list_op"] = []
  context["classification_arch_infer"] = ['AlexNetNCHW','MobileNetV2NCHW','MobileNetV2Cifar10NCHW']
  context["classification_arch_train"] = ['MobileNetV2NCHW','MobileNetV2Cifar10NCHW']
  config["mem_use_limit"] = 10
  config['multigpu'] = False
  config['VERBOSE'] = 0
  config['DEBUG'] = False

  with open('config_teplate.cfg', 'w') as configfile:
    config.write(configfile)


########################################
##                Main                ##
########################################


def main():
  parser = argparse.ArgumentParser()
  parser.add_argument('--commit',         "-c",    type=str,  default="master",   help='git commit hash used to execute bench')
  parser.add_argument('--config-file',    "-cf",   type=str,  default="",         help='overwrite all other command except project name.')
  parser.add_argument('--gen_all_res',    "-gar",  action='store_true',           help='Run all bench')
  parser.add_argument('--interactive',    "-i",    action='store_true',           help='overwrite all other command except project name.')
  parser.add_argument('--lib_path',       "-lp",   type=str, default="",          help='Used to indicate where is _upstride.so')
  parser.add_argument('--multigpu',       "-mg",   action='store_true',           help='Enable multi-GPU or not')
  parser.add_argument('--project_name',   "-pn",   type=str, default="phoenix_tf",help='Default: phoenix_tf')
  parser.add_argument('--result_dir',     "-rd",   type=str, default="",          help='Default: \'\'')
  parser.add_argument('--px_engine_path', "-pxep", type=str, default="",          help='Used to indicate where is located the Phoenix engine')
  parser.add_argument('--py_engine_path', "-pyep", type=str, default="",          help='Used to indicate where is located the python engine')
  parser.add_argument('--update',         "-u",    action='store_true',           help='Update and compile engine')
  parser.add_argument('--verbose',        "-v",    type=int, default=5,           help='Update and compile engine')
  parser.add_argument('--batch_size_init',"-b",    type=int, default=0,           help='First batch size that the script is going to try. '
                                                                                       'If no value is passed, its default value on each use case is applied.')
  args = parser.parse_args()

  # Either run following steps
  # Or ask to the user what he want to run
  # Only "general_all_res" can be ran if not in interactive mode
  if (not args.interactive):
    print_info = True
    update = False
    general_all_res = args.gen_all_res
    collect_op = False
    generate_op = False
    generate_nn = False
    classification_infer = False
    classification_train = False
  else:
    txt = input("Print sys info? y/N ")
    print_info = True if (txt == "y") else False
    txt = input("Pull and compile? y/N ")
    if txt == "y":
      update = True
      txt = input("From which branch or commit? (Type a branch name, commit hash or nothing for master)")
      context["commit"] = txt if txt else "master"
    else:
      update = False
      context["commit"] = get_git_revisions_hash()

    txt = input("Run all benchmarks? y/N ")
    if txt == "y":
      general_all_res = True
      collect_op = False
      generate_op = False
      generate_nn = False
      classification_infer = False
      classification_train = False
    else:
      general_all_res = False
      txt = input("Collect data by operation (scripts/*_bench.py)? y/N ")
      collect_op = True if (txt == "y") else False
      txt = input("Generate graph from previous collected data (by op)? y/N ")
      generate_op = True if (txt == "y") else False
      txt = input("Generate graph from small NN sample? y/N ")
      generate_nn = True if (txt == "y") else False
      txt = input("Run classification-api (inference) ? y/N ")
      classification_infer = True if (txt == "y") else False
      if classification_infer:
        txt = input("[classification-api][inf] on AlexNet ? y/N ")
        if txt == 'y':
          context["classification_arch_infer"].append('AlexNetNCHW')
        txt = input("[classification-api][inf] on MobileNetV2Cifar10 ? y/N ")
        if txt == 'y':
          context["classification_arch_infer"].append('MobileNetV2Cifar10NCHW')
        txt = input("[classification-api][inf] on MobileNetV2 ? y/N ")
        if txt == 'y':
          context["classification_arch_infer"].append('MobileNetV2NCHW')
      txt = input("Run classification-api (training) ? y/N ")
      classification_train = True if (txt == "y") else False
      if classification_train:
        txt = input("[classification-api][train] on MobileNetV2Cifar10 ? y/N ")
        if txt == 'y':
          context["classification_arch_train"].append('MobileNetV2Cifar10NCHW')
        txt = input("[classification-api][train] on MobileNetV2 ? y/N ")
        if txt == 'y':
          context["classification_arch_train"].append('MobileNetV2NCHW')

  fill_context(args=args,
               project_name=args.project_name,
               commit=args.commit,
               pypath=args.py_engine_path if args.py_engine_path else os.path.join(get_project_path(), "../upstride_python"),  # TODO: this should not be default path but it's easier for me
               pxpath=args.px_engine_path if args.px_engine_path else os.path.join(get_project_path(), "src/python"),
               resdir=args.result_dir,
               lib_path=args.lib_path,
               multigpu=True if args.multigpu else False,
               verbose=args.verbose)

  set_gpu_use(get_available_gpus())
  setup_env()
  write_generic_info()

  if print_info:
    print_generic_info()

  if update:
    update_engine()
    compile_engine(full_clean=False)

  # Plot and generating res
  generate_all_results(collect_op=collect_op or general_all_res,
                       generate_op=generate_op or general_all_res,
                       generate_nn=generate_nn or general_all_res,
                       classification_infer=classification_infer or general_all_res,
                       classification_train=classification_train or general_all_res)
  # if results directory exists and contains results
  if os.path.exists(context["resdir"]) and len(os.listdir(context["resdir"])) > 1:
    pack_results()
  else:
    print_warning("No results found. You should check previous process messages for more information.")
  
  os.environ['PYTHONPATH'] = context["orig_pythonpath"]

if __name__ == "__main__":
  main()
